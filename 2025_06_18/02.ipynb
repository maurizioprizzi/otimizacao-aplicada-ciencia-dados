{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXEMPLO 2: OTIMIZAÇÃO CONTÍNUA DE THRESHOLD COM BUSCA TERNÁRIA\n",
    "# Modelagem Matemática Aplicada à Otimização em Análise de Dados\n",
    "# Prof. Maurizio Prizzi - CEUB\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "OBJETIVO: Demonstrar como otimizar continuamente o threshold de classificação\n",
    "para adaptação em tempo real a mudanças nos padrões de fraude (concept drift).\n",
    "\n",
    "CONCEITOS MATEMÁTICOS:\n",
    "- Busca ternária para otimização de função unimodal\n",
    "- Otimização contínua e adaptação online\n",
    "- Análise de sensibilidade de parâmetros\n",
    "- Convergência de algoritmos de busca\n",
    "- Simulação de concept drift\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Importando bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize_scalar\n",
    "import time\n",
    "import logging\n",
    "from functools import lru_cache\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurando logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"=\" * 80)\n",
    "logger.info(\"EXEMPLO 2: OTIMIZAÇÃO CONTÍNUA DE THRESHOLD COM BUSCA TERNÁRIA\")\n",
    "logger.info(\"Adaptação em tempo real\")\n",
    "logger.info(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. GERAÇÃO DE DATASET E TREINAMENTO DE MODELO BASE\n",
    "# ============================================================================\n",
    "\n",
    "def criar_modelo_pre_treinado():\n",
    "    \"\"\"\n",
    "    Cria e treina um modelo base para demonstrar a otimização de threshold\n",
    "    Simula um modelo já em produção que precisa de calibração contínua\n",
    "    \"\"\"\n",
    "    logger.info(\"Criando modelo base para otimização de threshold...\")\n",
    "\n",
    "    # Dataset sintético para modelo base\n",
    "    X, y = make_classification(\n",
    "        n_samples=12000,\n",
    "        n_features=15,\n",
    "        n_informative=12,\n",
    "        n_clusters_per_class=3,\n",
    "        weights=[0.95, 0.05],  # 95% legítimas, 5% fraudes\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Nomes das features para modelo de fraude\n",
    "    feature_names = [\n",
    "        'valor_log', 'velocidade_transacao', 'freq_horaria', 'desvio_comportamental',\n",
    "        'score_dispositivo', 'historico_localizacao', 'padrão_temporal',\n",
    "        'network_risk', 'account_age', 'transaction_count', 'velocity_score',\n",
    "        'geo_anomaly', 'device_fingerprint', 'behavioral_score', 'risk_aggregate'\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    df['fraude'] = y\n",
    "\n",
    "    # Divisão e treinamento\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Modelo Random Forest pré-configurado\n",
    "    modelo = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Treinamento\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    # Probabilidades para otimização de threshold\n",
    "    y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    logger.info(f\"Modelo base treinado:\")\n",
    "    logger.info(f\"   Dataset: {len(df):,} transações\")\n",
    "    logger.info(f\"   Conjunto teste: {len(X_test):,} transações\")\n",
    "    logger.info(f\"   Taxa de fraude: {sum(y_test)/len(y_test)*100:.1f}%\")\n",
    "\n",
    "    return y_test, y_proba, df, X_test, y_train, X_train\n",
    "\n",
    "# Criando modelo e obtendo dados para otimização\n",
    "y_true, probabilidades, dados_completos, X_test, y_train, X_train = criar_modelo_pre_treinado()\n",
    "\n",
    "# ============================================================================\n",
    "# 2. FUNÇÃO OBJETIVO PARA OTIMIZAÇÃO DE THRESHOLD\n",
    "# ============================================================================\n",
    "\n",
    "def calcular_metricas_negocio(threshold, y_true, y_proba):\n",
    "    \"\"\"\n",
    "    Calcula métricas de negócio para um threshold específico\n",
    "\n",
    "    Parâmetros:\n",
    "    - threshold: Ponto de corte para classificação (0 < threshold < 1)\n",
    "    - y_true: Labels verdadeiros\n",
    "    - y_proba: Probabilidades preditas pelo modelo\n",
    "\n",
    "    Retorna: Dicionário com métricas calculadas\n",
    "    \"\"\"\n",
    "    # Validação de entrada\n",
    "    if not (len(y_true) == len(y_proba) and len(y_true) > 0):\n",
    "        raise ValueError(\"y_true e y_proba devem ter o mesmo tamanho e não podem ser vazios\")\n",
    "    if not np.all((0 <= y_proba) & (y_proba <= 1)):\n",
    "        raise ValueError(\"y_proba deve conter valores entre 0 e 1\")\n",
    "    if not np.all(np.isin(y_true, [0, 1])):\n",
    "        raise ValueError(\"y_true deve conter apenas 0 ou 1\")\n",
    "\n",
    "    # Aplicando threshold para gerar predições binárias\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    # Métricas fundamentais\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    # Matriz de confusão\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    # Métricas derivadas com regularização\n",
    "    denominador = tn + fp + 1e-10  # Evita divisão por zero\n",
    "    especificidade = tn / denominador\n",
    "    fpr = fp / denominador\n",
    "    fnr = fn / (fn + tp + 1e-10)\n",
    "\n",
    "    return {\n",
    "        'threshold': threshold,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'especificidade': especificidade,\n",
    "        'fpr': fpr,\n",
    "        'fnr': fnr,\n",
    "        'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn\n",
    "    }\n",
    "\n",
    "@lru_cache(maxsize=1000)\n",
    "def funcao_objetivo_threshold(threshold, y_true_tuple, y_proba_tuple,\n",
    "                             peso_recall=0.6, peso_precision=0.25, peso_experiencia=0.15):\n",
    "    \"\"\"\n",
    "    Função objetivo para otimizar threshold baseada em critérios de negócio\n",
    "\n",
    "    Combina múltiplos objetivos:\n",
    "    - Maximizar recall (detectar fraudes)\n",
    "    - Maximizar precisão (evitar falsos alarmes)\n",
    "    - Maximizar experiência do usuário (baixo FPR)\n",
    "\n",
    "    Retorna: Valor a ser MAXIMIZADO\n",
    "    \"\"\"\n",
    "    # Converter tuplas de volta para arrays\n",
    "    y_true = np.array(y_true_tuple)\n",
    "    y_proba = np.array(y_proba_tuple)\n",
    "\n",
    "    # Calculando métricas\n",
    "    metricas = calcular_metricas_negocio(threshold, y_true, y_proba)\n",
    "\n",
    "    # Score combinado usando pesos de negócio\n",
    "    score = (peso_recall * metricas['recall'] +\n",
    "             peso_precision * metricas['precision'] +\n",
    "             peso_experiencia * metricas['especificidade'])\n",
    "\n",
    "    return score\n",
    "\n",
    "# ============================================================================\n",
    "# 3. IMPLEMENTAÇÃO DA BUSCA TERNÁRIA\n",
    "# ============================================================================\n",
    "\n",
    "def avaliar_pontos_ternarios(left, right, y_true, y_proba, peso_recall, peso_precision, peso_experiencia):\n",
    "    \"\"\"\n",
    "    Avalia os pontos de divisão ternária e retorna valores da função objetivo\n",
    "    \"\"\"\n",
    "    delta = (right - left) / 3\n",
    "    m1 = left + delta\n",
    "    m2 = right - delta\n",
    "    f_m1 = funcao_objetivo_threshold(m1, tuple(y_true), tuple(y_proba),\n",
    "                                     peso_recall, peso_precision, peso_experiencia)\n",
    "    f_m2 = funcao_objetivo_threshold(m2, tuple(y_true), tuple(y_proba),\n",
    "                                     peso_recall, peso_precision, peso_experiencia)\n",
    "    return m1, m2, f_m1, f_m2\n",
    "\n",
    "def busca_ternaria_otimizada(y_true, y_proba, peso_recall=0.6, peso_precision=0.25,\n",
    "                             peso_experiencia=0.15, tolerancia=1e-7, max_iteracoes=100):\n",
    "    \"\"\"\n",
    "    Implementa busca ternária para encontrar threshold ótimo\n",
    "\n",
    "    A busca ternária é eficiente para funções unimodais (um único máximo global)\n",
    "    Complexidade: O(log₃(n)) onde n é o tamanho do espaço de busca\n",
    "\n",
    "    Parâmetros:\n",
    "    - tolerancia: Precisão desejada para convergência\n",
    "    - max_iteracoes: Número máximo de iterações\n",
    "\n",
    "    Retorna: threshold_otimo, score_otimo, historico_convergencia\n",
    "    \"\"\"\n",
    "    logger.info(\"Iniciando Busca Ternária para Threshold Ótimo...\")\n",
    "    logger.info(f\"   Tolerância: {tolerancia}\")\n",
    "    logger.info(f\"   Máx. iterações: {max_iteracoes}\")\n",
    "\n",
    "    # Intervalo inicial de busca\n",
    "    left = 0.001\n",
    "    right = 0.999\n",
    "\n",
    "    # Histórico para análise de convergência\n",
    "    historico = []\n",
    "\n",
    "    inicio_tempo = time.time()\n",
    "\n",
    "    for iteracao in range(max_iteracoes):\n",
    "        # Avaliar pontos ternários\n",
    "        m1, m2, f_m1, f_m2 = avaliar_pontos_ternarios(\n",
    "            left, right, y_true, y_proba, peso_recall, peso_precision, peso_experiencia\n",
    "        )\n",
    "\n",
    "        # Salvando histórico\n",
    "        historico.append({\n",
    "            'iteracao': iteracao + 1,\n",
    "            'left': left,\n",
    "            'right': right,\n",
    "            'm1': m1,\n",
    "            'm2': m2,\n",
    "            'f_m1': f_m1,\n",
    "            'f_m2': f_m2,\n",
    "            'intervalo_size': right - left\n",
    "        })\n",
    "\n",
    "        # Atualização do intervalo\n",
    "        if f_m1 > f_m2:\n",
    "            right = m2\n",
    "        else:\n",
    "            left = m1\n",
    "\n",
    "        # Critério de convergência\n",
    "        if (right - left) < tolerancia:\n",
    "            logger.info(f\"   Convergência atingida na iteração {iteracao + 1}\")\n",
    "            break\n",
    "\n",
    "        # Progresso a cada 10 iterações\n",
    "        if (iteracao + 1) % 10 == 0:\n",
    "            logger.info(f\"   Iteração {iteracao + 1}: intervalo = [{left:.6f}, {right:.6f}]\")\n",
    "\n",
    "    # Threshold ótimo é o ponto médio do intervalo final\n",
    "    threshold_otimo = (left + right) / 2\n",
    "    score_otimo = funcao_objetivo_threshold(threshold_otimo, tuple(y_true), tuple(y_proba),\n",
    "                                            peso_recall, peso_precision, peso_experiencia)\n",
    "\n",
    "    tempo_execucao = time.time() - inicio_tempo\n",
    "\n",
    "    logger.info(\"Busca Ternária Concluída:\")\n",
    "    logger.info(f\"   Tempo de execução: {tempo_execucao:.3f} segundos\")\n",
    "    logger.info(f\"   Iterações realizadas: {len(historico)}\")\n",
    "    logger.info(f\"   Threshold ótimo: {threshold_otimo:.6f}\")\n",
    "    logger.info(f\"   Score ótimo: {score_otimo:.6f}\")\n",
    "\n",
    "    return threshold_otimo, score_otimo, historico\n",
    "\n",
    "# ============================================================================\n",
    "# 4. EXECUÇÃO DA OTIMIZAÇÃO DE THRESHOLD\n",
    "# ============================================================================\n",
    "\n",
    "# Executando busca ternária com pesos de negócio customizados\n",
    "threshold_otimo, score_otimo, historico_convergencia = busca_ternaria_otimizada(\n",
    "    y_true, probabilidades,\n",
    "    peso_recall=0.65,\n",
    "    peso_precision=0.25,\n",
    "    peso_experiencia=0.10,\n",
    "    tolerancia=1e-8,\n",
    "    max_iteracoes=150\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. COMPARAÇÃO: THRESHOLD PADRÃO VS OTIMIZADO\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"Comparando Performance: Threshold Padrão vs Otimizado\")\n",
    "\n",
    "# Métricas com threshold padrão (0.5)\n",
    "metricas_padrao = calcular_metricas_negocio(0.5, y_true, probabilidades)\n",
    "\n",
    "# Métricas com threshold otimizado\n",
    "metricas_otimizado = calcular_metricas_negocio(threshold_otimo, y_true, probabilidades)\n",
    "\n",
    "# Criando DataFrame comparativo\n",
    "comparacao_df = pd.DataFrame({\n",
    "    'Threshold Padrão (0.5)': [\n",
    "        metricas_padrao['precision'],\n",
    "        metricas_padrao['recall'],\n",
    "        metricas_padrao['f1_score'],\n",
    "        metricas_padrao['fpr'],\n",
    "        metricas_padrao['fnr']\n",
    "    ],\n",
    "    'Threshold Otimizado': [\n",
    "        metricas_otimizado['precision'],\n",
    "        metricas_otimizado['recall'],\n",
    "        metricas_otimizado['f1_score'],\n",
    "        metricas_otimizado['fpr'],\n",
    "        metricas_otimizado['fnr']\n",
    "    ]\n",
    "}, index=['Precision', 'Recall', 'F1-Score', 'Taxa FP', 'Taxa FN'])\n",
    "\n",
    "logger.info(\"\\nComparação Detalhada:\")\n",
    "logger.info(\"\\n\" + str(comparacao_df.round(4)))\n",
    "\n",
    "# Calculando melhorias percentuais\n",
    "melhorias = {}\n",
    "for metrica in ['precision', 'recall', 'f1_score']:\n",
    "    valor_padrao = metricas_padrao[metrica]\n",
    "    valor_otimizado = metricas_otimizado[metrica]\n",
    "    if valor_padrao > 0:\n",
    "        melhoria = ((valor_otimizado - valor_padrao) / valor_padrao) * 100\n",
    "        melhorias[metrica] = melhoria\n",
    "\n",
    "logger.info(\"Melhorias Alcançadas:\")\n",
    "logger.info(f\"   Recall: {melhorias['recall']:+.1f}%\")\n",
    "logger.info(f\"   Precision: {melhorias['precision']:+.1f}%\")\n",
    "logger.info(f\"   F1-Score: {melhorias['f1_score']:+.1f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. VISUALIZAÇÕES ESPECÍFICAS DO EXEMPLO 2\n",
    "# ============================================================================\n",
    "\n",
    "# Configuração para plots\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = [15, 12]\n",
    "\n",
    "# Criando subplots para múltiplas visualizações\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# PLOT 1: Convergência da Busca Ternária (agora em ChartJS, renderizado separadamente)\n",
    "# JSON para ChartJS\n",
    "chartjs_data = {\n",
    "    \"type\": \"line\",\n",
    "    \"data\": {\n",
    "        \"labels\": list(range(1, len(historico_convergencia) + 1)),\n",
    "        \"datasets\": [\n",
    "            {\n",
    "                \"label\": \"Limite Inferior\",\n",
    "                \"data\": [h['left'] for h in historico_convergencia],\n",
    "                \"borderColor\": \"#1E90FF\",\n",
    "                \"backgroundColor\": \"#1E90FF\",\n",
    "                \"fill\": False,\n",
    "                \"tension\": 0.1\n",
    "            },\n",
    "            {\n",
    "                \"label\": \"Limite Superior\",\n",
    "                \"data\": [h['right'] for h in historico_convergencia],\n",
    "                \"borderColor\": \"#FF4500\",\n",
    "                \"backgroundColor\": \"#FF4500\",\n",
    "                \"fill\": False,\n",
    "                \"tension\": 0.1\n",
    "            },\n",
    "            {\n",
    "                \"label\": f\"Threshold Ótimo: {threshold_otimo:.4f}\",\n",
    "                \"data\": [threshold_otimo] * len(historico_convergencia),\n",
    "                \"borderColor\": \"#32CD32\",\n",
    "                \"backgroundColor\": \"#32CD32\",\n",
    "                \"borderDash\": [5, 5],\n",
    "                \"fill\": False,\n",
    "                \"tension\": 0.1\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"options\": {\n",
    "        \"plugins\": {\n",
    "            \"title\": {\n",
    "                \"display\": True,\n",
    "                \"text\": \"Convergência da Busca Ternária\",\n",
    "                \"font\": {\"size\": 16, \"weight\": \"bold\"}\n",
    "            },\n",
    "            \"legend\": {\"position\": \"top\"}\n",
    "        },\n",
    "        \"scales\": {\n",
    "            \"x\": {\"title\": {\"display\": True, \"text\": \"Iteração\"}},\n",
    "            \"y\": {\"title\": {\"display\": True, \"text\": \"Threshold\"}, \"min\": 0, \"max\": 1}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "logger.info(\"ChartJS para Convergência da Busca Ternária gerado (renderizar separadamente)\")\n",
    "\n",
    "# PLOT 2: Tamanho do Intervalo de Busca\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "hist_df = pd.DataFrame(historico_convergencia)\n",
    "ax2.semilogy(hist_df['iteracao'], hist_df['intervalo_size'], 'purple', linewidth=2, marker='o', markersize=4)\n",
    "ax2.set_xlabel('Iteração')\n",
    "ax2.set_ylabel('Tamanho do Intervalo (log)')\n",
    "ax2.set_title('Redução do Intervalo de Busca', fontweight='bold', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# PLOT 3: Função Objetivo vs Threshold (Análise de Sensibilidade)\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "thresholds_teste = np.linspace(0.01, 0.99, 200)\n",
    "scores_teste = [funcao_objetivo_threshold(t, tuple(y_true), tuple(y_proba), 0.65, 0.25, 0.10)\n",
    "                for t in thresholds_teste]\n",
    "\n",
    "ax3.plot(thresholds_teste, scores_teste, 'blue', linewidth=2)\n",
    "ax3.axvline(x=threshold_otimo, color='red', linestyle='--', linewidth=2,\n",
    "            label=f'Ótimo: {threshold_otimo:.4f}')\n",
    "ax3.axvline(x=0.5, color='gray', linestyle=':', linewidth=2, label='Padrão: 0.5')\n",
    "ax3.set_xlabel('Threshold')\n",
    "ax3.set_ylabel('Score da Função Objetivo')\n",
    "ax3.set_title('Análise de Sensibilidade', fontweight='bold', fontsize=12)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# PLOT 4: Comparação de Métricas (Bar Plot)\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "x_pos = np.arange(len(comparacao_df.index))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax4.bar(x_pos - width/2, comparacao_df['Threshold Padrão (0.5)'],\n",
    "                width, label='Threshold Padrão', color='lightcoral', alpha=0.8)\n",
    "bars2 = ax4.bar(x_pos + width/2, comparacao_df['Threshold Otimizado'],\n",
    "                width, label='Threshold Otimizado', color='lightblue', alpha=0.8)\n",
    "\n",
    "ax4.set_xlabel('Métricas')\n",
    "ax4.set_ylabel('Valor')\n",
    "ax4.set_title('Comparação de Performance', fontweight='bold', fontsize=12)\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(comparacao_df.index, rotation=45)\n",
    "ax4.legend()\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Adicionando valores nas barras\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# PLOT 5: Curvas Precision-Recall e ROC\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "precisions, recalls, fprs = [], [], []\n",
    "thresholds_curva = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "for t in thresholds_curva:\n",
    "    metricas = calcular_metricas_negocio(t, y_true, probabilidades)\n",
    "    precisions.append(metricas['precision'])\n",
    "    recalls.append(metricas['recall'])\n",
    "    fprs.append(metricas['fpr'])\n",
    "\n",
    "ax5.plot(recalls, precisions, 'b-', linewidth=2, label='Curva Precision-Recall')\n",
    "idx_otimo = np.argmin(np.abs(np.array(thresholds_curva) - threshold_otimo))\n",
    "idx_padrao = np.argmin(np.abs(np.array(thresholds_curva) - 0.5))\n",
    "\n",
    "ax5.plot(recalls[idx_otimo], precisions[idx_otimo], 'ro', markersize=10,\n",
    "         label=f'Otimizado ({threshold_otimo:.3f})')\n",
    "ax5.plot(recalls[idx_padrao], precisions[idx_padrao], 'go', markersize=10,\n",
    "         label='Padrão (0.5)')\n",
    "ax5.set_xlabel('Recall')\n",
    "ax5.set_ylabel('Precision')\n",
    "ax5.set_title('Curva Precision-Recall', fontweight='bold', fontsize=12)\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# PLOT 6: Distribuição de Probabilidades\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "prob_legitimas = probabilidades[y_true == 0]\n",
    "prob_fraudes = probabilidades[y_true == 1]\n",
    "\n",
    "ax6.hist(prob_legitimas, bins=50, alpha=0.6, label='Transações Legítimas',\n",
    "         color='lightgreen', density=True)\n",
    "ax6.hist(prob_fraudes, bins=50, alpha=0.6, label='Fraudes',\n",
    "         color='lightcoral', density=True)\n",
    "\n",
    "ax6.axvline(x=0.5, color='gray', linestyle=':', linewidth=2, label='Threshold Padrão')\n",
    "ax6.axvline(x=threshold_otimo, color='red', linestyle='--', linewidth=2,\n",
    "            label=f'Threshold Otimizado')\n",
    "ax6.set_xlabel('Probabilidade de Fraude')\n",
    "ax6.set_ylabel('Densidade')\n",
    "ax6.set_title('Distribuição de Probabilidades', fontweight='bold', fontsize=12)\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 7. SIMULAÇÃO DE ADAPTAÇÃO CONTÍNUA (CONCEPT DRIFT)\n",
    "# ============================================================================\n",
    "\n",
    "def simular_concept_drift_temporal(X_train, y_train, X_test, y_true):\n",
    "    \"\"\"\n",
    "    Simula mudanças nos padrões de fraude ao longo do tempo\n",
    "    e demonstra como o threshold deve ser continuamente re-otimizado\n",
    "    \"\"\"\n",
    "    logger.info(\"Simulando Adaptação Contínua ao Concept Drift...\")\n",
    "\n",
    "    # Simulando 12 períodos mensais\n",
    "    n_periodos = 12\n",
    "    resultados_tempo = []\n",
    "    modelo = RandomForestClassifier(\n",
    "        n_estimators=200, max_depth=20, min_samples_split=5, random_state=42, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    for mes in range(1, n_periodos + 1):\n",
    "        logger.info(f\"Processando Mês {mes}/12\")\n",
    "\n",
    "        # Simulando drift nas features\n",
    "        drift_factor = 1.0 + 0.03 * mes\n",
    "        seasonal_factor = 1.0 + 0.2 * np.sin(2 * np.pi * mes / 12)\n",
    "        X_drift, y_drift = make_classification(\n",
    "            n_samples=12000,\n",
    "            n_features=15,\n",
    "            n_informative=12,\n",
    "            n_clusters_per_class=3,\n",
    "            weights=[0.95 - 0.01 * mes, 0.05 + 0.01 * mes],  # Aumenta fraudes\n",
    "            random_state=42 + mes,\n",
    "            shift=drift_factor * 0.1,\n",
    "            scale=seasonal_factor\n",
    "        )\n",
    "\n",
    "        # Re-treinar modelo para o período\n",
    "        modelo.fit(X_train, y_train)\n",
    "        prob_drift = modelo.predict_proba(X_drift)[:, 1]\n",
    "\n",
    "        # Aplicando ruído nas probabilidades\n",
    "        ruido = np.random.normal(1.0, 0.05, len(prob_drift))\n",
    "        prob_drift = prob_drift * drift_factor * seasonal_factor * ruido\n",
    "        prob_drift = np.clip(prob_drift, 0.001, 0.999)\n",
    "\n",
    "        # Re-otimizando threshold\n",
    "        threshold_mes, score_mes, _ = busca_ternaria_otimizada(\n",
    "            y_drift, prob_drift,\n",
    "            peso_recall=0.65, peso_precision=0.25, peso_experiencia=0.10,\n",
    "            tolerancia=1e-6, max_iteracoes=50\n",
    "        )\n",
    "\n",
    "        # Calculando métricas\n",
    "        metricas_mes = calcular_metricas_negocio(threshold_mes, y_drift, prob_drift)\n",
    "\n",
    "        # Salvando resultados\n",
    "        resultados_tempo.append({\n",
    "            'mes': mes,\n",
    "            'threshold': threshold_mes,\n",
    "            'score': score_mes,\n",
    "            'precision': metricas_mes['precision'],\n",
    "            'recall': metricas_mes['recall'],\n",
    "            'f1_score': metricas_mes['f1_score'],\n",
    "            'fpr': metricas_mes['fpr'],\n",
    "            'drift_factor': drift_factor,\n",
    "            'seasonal_factor': seasonal_factor\n",
    "        })\n",
    "\n",
    "        logger.info(f\"   Threshold: {threshold_mes:.4f}, F1: {metricas_mes['f1_score']:.3f}\")\n",
    "\n",
    "    return pd.DataFrame(resultados_tempo)\n",
    "\n",
    "# Executando simulação\n",
    "logger.info(\"Executando simulação de 12 meses...\")\n",
    "resultados_drift = simular_concept_drift_temporal(X_train, y_train, X_test, y_true)\n",
    "\n",
    "# ============================================================================\n",
    "# 8. VISUALIZAÇÃO DA ADAPTAÇÃO TEMPORAL\n",
    "# ============================================================================\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Evolução do Threshold ao longo do tempo\n",
    "ax1.plot(resultados_drift['mes'], resultados_drift['threshold'], 'bo-', linewidth=2, markersize=6)\n",
    "ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7, label='Threshold Padrão')\n",
    "ax1.set_xlabel('Mês')\n",
    "ax1.set_ylabel('Threshold Ótimo')\n",
    "ax1.set_title('Adaptação do Threshold ao Longo do Tempo', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Performance (F1-Score) ao longo do tempo\n",
    "ax2.plot(resultados_drift['mes'], resultados_drift['f1_score'], 'ro-', linewidth=2, markersize=6)\n",
    "ax2.set_xlabel('Mês')\n",
    "ax2.set_ylabel('F1-Score')\n",
    "ax2.set_title('Performance Mantida com Adaptação', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Fatores de Drift\n",
    "ax3.plot(resultados_drift['mes'], resultados_drift['drift_factor'], 'g-',\n",
    "         linewidth=2, label='Drift Linear')\n",
    "ax3.plot(resultados_drift['mes'], resultados_drift['seasonal_factor'], 'orange',\n",
    "         linewidth=2, label='Fator Sazonal')\n",
    "ax3.set_xlabel('Mês')\n",
    "ax3.set_ylabel('Fator de Multiplicação')\n",
    "ax3.set_title('Fatores de Concept Drift Simulados', fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Trade-off Precision vs Recall\n",
    "ax4.scatter(resultados_drift['recall'], resultados_drift['precision'],\n",
    "           c=resultados_drift['mes'], cmap='viridis', s=100, alpha=0.7)\n",
    "ax4.set_xlabel('Recall')\n",
    "ax4.set_ylabel('Precision')\n",
    "ax4.set_title('Trade-off Precision-Recall ao Longo do Tempo', fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "cbar = plt.colorbar(ax4.collections[0], ax=ax4)\n",
    "cbar.set_label('Mês')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 9. ANÁLISE DE COMPLEXIDADE ALGORÍTMICA\n",
    "# ============================================================================\n",
    "\n",
    "def analisar_complexidade_busca_ternaria():\n",
    "    \"\"\"\n",
    "    Demonstra a eficiência da busca ternária comparada com busca linear\n",
    "    \"\"\"\n",
    "    logger.info(\"Análise de Complexidade: Busca Ternária vs Linear\")\n",
    "\n",
    "    tamanhos_teste = [100, 1000, 10000, 100000]\n",
    "    resultados_complexidade = []\n",
    "\n",
    "    for n in tamanhos_teste:\n",
    "        inicio = time.time()\n",
    "        for _ in range(n):\n",
    "            funcao_objetivo_threshold(0.5, tuple(y_true[:100]), tuple(probabilidades[:100]))\n",
    "        tempo_linear = time.time() - inicio\n",
    "\n",
    "        iteracoes_ternaria = int(np.log(n) / np.log(3)) + 1\n",
    "        inicio = time.time()\n",
    "        for _ in range(iteracoes_ternaria):\n",
    "            funcao_objetivo_threshold(0.5, tuple(y_true[:100]), tuple(probabilidades[:100]))\n",
    "        tempo_ternaria = time.time() - inicio\n",
    "\n",
    "        resultados_complexidade.append({\n",
    "            'n': n,\n",
    "            'tempo_linear': tempo_linear,\n",
    "            'tempo_ternaria': tempo_ternaria,\n",
    "            'iteracoes_ternaria': iteracoes_ternaria,\n",
    "            'speedup': tempo_linear / tempo_ternaria if tempo_ternaria > 0 else 0\n",
    "        })\n",
    "\n",
    "        logger.info(f\"   n={n:6d}: Linear={tempo_linear:.4f}s, Ternária={tempo_ternaria:.4f}s, \"\n",
    "                    f\"Speedup={tempo_linear/tempo_ternaria if tempo_ternaria > 0 else 0:.1f}x\")\n",
    "\n",
    "    return pd.DataFrame(resultados_complexidade)\n",
    "\n",
    "complexidade_df = analisar_complexidade_busca_ternaria()\n",
    "\n",
    "# ============================================================================\n",
    "# 10. RELATÓRIO FINAL E INSIGHTS\n",
    "# ============================================================================\n",
    "\n",
    "logger.info(\"=\" * 80)\n",
    "logger.info(\"RELATÓRIO FINAL - EXEMPLO 2: OTIMIZAÇÃO CONTÍNUA DE THRESHOLD\")\n",
    "logger.info(\"=\" * 80)\n",
    "\n",
    "logger.info(f\"\"\"\n",
    "PRINCIPAIS RESULTADOS:\n",
    "\n",
    "Otimização de Threshold:\n",
    "   • Threshold padrão: 0.500\n",
    "   • Threshold otimizado: {threshold_otimo:.6f}\n",
    "   • Melhoria F1-Score: {melhorias['f1_score']:+.1f}%\n",
    "   • Melhoria Recall: {melhorias['recall']:+.1f}%\n",
    "\n",
    "Eficiência Algorítmica:\n",
    "   • Busca ternária: O(log₃ n) iterações\n",
    "   • Convergência em {len(historico_convergencia)} iterações\n",
    "   • Speedup médio: {complexidade_df['speedup'].mean():.1f}x vs busca linear\n",
    "\n",
    "Adaptação Contínua:\n",
    "   • Simulação de 12 meses com concept drift\n",
    "   • Threshold varia de {resultados_drift['threshold'].min():.3f} a {resultados_drift['threshold'].max():.3f}\n",
    "   • Performance F1 mantida em {resultados_drift['f1_score'].mean():.3f} ± {resultados_drift['f1_score'].std():.3f}\n",
    "\n",
    "APLICAÇÕES PRÁTICAS:\n",
    "\n",
    "1. Calibração Automática em Produção:\n",
    "   • Re-otimização de threshold a cada período (diário/semanal)\n",
    "   • Adaptação automática a mudanças nos padrões de fraude\n",
    "   • Monitoramento contínuo de performance\n",
    "\n",
    "2. Sistemas de Alerta Adaptativos:\n",
    "   • Ajuste dinâmico baseado em feedback do negócio\n",
    "   • Balanceamento automático entre detecção e experiência\n",
    "   • Resposta rápida a novos tipos de fraude\n",
    "\n",
    "3. A/B Testing de Thresholds:\n",
    "   • Comparação de diferentes configurações em produção\n",
    "   • Otimização baseada em métricas de negócio específicas\n",
    "   • Rollback automático em caso de degradação\n",
    "\n",
    "CONCEITOS MATEMÁTICOS DEMONSTRADOS:\n",
    "\n",
    "• Busca ternária para otimização de função unimodal\n",
    "• Análise de convergência e complexidade algorítmica\n",
    "• Otimização contínua com restrições de domínio\n",
    "• Simulação de concept drift temporal\n",
    "• Trade-off entre múltiplos objetivos conflitantes\n",
    "\n",
    "MÉTRICAS FINAIS DE NEGÓCIO:\n",
    "\n",
    "• Taxa de detecção otimizada: {metricas_otimizado['recall']:.1%}\n",
    "• Qualidade das detecções: {metricas_otimizado['precision']:.1%}\n",
    "• Taxa de falsos positivos: {metricas_otimizado['fpr']:.2%}\n",
    "• Score F1 balanceado: {metricas_otimizado['f1_score']:.3f}\n",
    "\n",
    "VANTAGENS DA ABORDAGEM:\n",
    "\n",
    "✓ Adaptação automática a mudanças nos dados\n",
    "✓ Eficiência computacional (complexidade logarítmica)\n",
    "✓ Flexibilidade para diferentes pesos de negócio\n",
    "✓ Monitoramento contínuo de performance\n",
    "✓ Escalabilidade para grandes volumes de dados\n",
    "\"\"\")\n",
    "\n",
    "logger.info(\"Integração com Exemplo 1:\")\n",
    "logger.info(\"   • Exemplo 1: Otimização de hiperparâmetros (decisão discreta)\")\n",
    "logger.info(\"   • Exemplo 2: Otimização de threshold (decisão contínua)\")\n",
    "logger.info(\"   • Juntos: Sistema completo de otimização multi-nível\")\n",
    "\n",
    "logger.info(\"Aplicação Industrial:\")\n",
    "logger.info(\"   • Similar ao pipeline para calibração contínua\")\n",
    "logger.info(\"   • Adaptação em tempo real a concept drift\")\n",
    "logger.info(\"   • Otimização automática de trade-offs de negócio\")\n",
    "\n",
    "logger.info(\"Exemplo 2 concluído com sucesso!\")\n",
    "logger.info(\"Prof. Maurizio Prizzi - maurizio.prizzi@ceub.edu.br\")\n",
    "logger.info(\"Repositório: https://github.com/maurizioprizzi/otimizacao-aplicada-ciencia-dados\")\n",
    "logger.info(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
