{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c884aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXEMPLO 1: OTIMIZA√á√ÉO DE HIPERPAR√ÇMETROS PARA DETEC√á√ÉO DE FRAUDES\n",
      "T√©cnicas inspiradas na Feedzai e outras fintechs l√≠deres\n",
      "================================================================================\n",
      "\n",
      "üìä Gerando dataset sint√©tico de transa√ß√µes banc√°rias...\n",
      "‚ö†Ô∏è Aviso: Propor√ß√£o de fraudes (0.051) fora do intervalo esperado (0.03-0.05).\n",
      "‚úÖ Dataset criado com sucesso!\n",
      "   üìà Total de transa√ß√µes: 15,000\n",
      "   ‚úÖ Transa√ß√µes leg√≠timas: 14,242 (94.9%)\n",
      "   üö® Transa√ß√µes fraudulentas: 758 (5.1%)\n",
      "\n",
      "üîß Preparando dados para modelagem...\n",
      "‚úÖ Dados preparados:\n",
      "   üìö Conjunto de treino: 11,250 transa√ß√µes\n",
      "   üß™ Conjunto de teste: 3,750 transa√ß√µes\n",
      "   üî¢ Features por transa√ß√£o: 18\n",
      "\n",
      "üéØ Definindo espa√ßo de busca para otimiza√ß√£o de hiperpar√¢metros...\n",
      "‚úÖ Espa√ßo de busca definido:\n",
      "   üîç Total de combina√ß√µes: 486\n",
      "   ‚è±Ô∏è Estimativa de tempo: ~49 segundos\n",
      "\n",
      "üöÄ Iniciando otimiza√ß√£o de hiperpar√¢metros...\n",
      "   ‚ö° Executando busca (pode levar alguns minutos)...\n",
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 255\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Executando a busca\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ‚ö° Executando busca (pode levar alguns minutos)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 255\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train_norm, y_train)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ Otimiza√ß√£o conclu√≠da!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   üèÜ Melhor score (CV): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m         clone(base_estimator),\n\u001b[1;32m    973\u001b[0m         X,\n\u001b[1;32m    974\u001b[0m         y,\n\u001b[1;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    981\u001b[0m     )\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    983\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    985\u001b[0m     )\n\u001b[1;32m    986\u001b[0m )\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXEMPLO 1: OTIMIZA√á√ÉO DE HIPERPAR√ÇMETROS PARA DETEC√á√ÉO DE FRAUDES\n",
    "# Modelagem Matem√°tica Aplicada √† Otimiza√ß√£o em An√°lise de Dados\n",
    "# Prof. Maurizio Prizzi - CEUB\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "OBJETIVO: Demonstrar como otimizar hiperpar√¢metros de modelos de Machine Learning\n",
    "para maximizar a detec√ß√£o de fraudes financeiras minimizando falsos positivos.\n",
    "\n",
    "CONCEITOS MATEM√ÅTICOS:\n",
    "- Otimiza√ß√£o multi-objetivo\n",
    "- Busca em grade (Grid Search) ou busca aleat√≥ria (Randomized Search)\n",
    "- Valida√ß√£o cruzada estratificada\n",
    "- Fun√ß√£o de fitness customizada\n",
    "- An√°lise de trade-offs\n",
    "\n",
    "VERS√ÉO REVISADA: Inclui corre√ß√µes de erros, melhorias de robustez e efici√™ncia.\n",
    "\"\"\"\n",
    "\n",
    "# Importando bibliotecas necess√°rias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXEMPLO 1: OTIMIZA√á√ÉO DE HIPERPAR√ÇMETROS PARA DETEC√á√ÉO DE FRAUDES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. GERA√á√ÉO DE DATASET SINT√âTICO DE TRANSA√á√ïES FINANCEIRAS\n",
    "# ============================================================================\n",
    "\n",
    "def criar_dataset_transacoes_financeiras():\n",
    "    \"\"\"\n",
    "    Cria um dataset sint√©tico que simula transa√ß√µes banc√°rias reais\n",
    "    com caracter√≠sticas t√≠picas de detec√ß√£o de fraude\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä Gerando dataset sint√©tico de transa√ß√µes banc√°rias...\")\n",
    "    \n",
    "    # Par√¢metros para simular dados realistas de transa√ß√µes\n",
    "    n_transacoes = 15000  # 15 mil transa√ß√µes\n",
    "    n_features = 18       # 18 caracter√≠sticas por transa√ß√£o\n",
    "    n_informativas = 14   # 14 features realmente √∫teis\n",
    "    \n",
    "    # Distribui√ß√£o desbalanceada t√≠pica: 96% leg√≠timas, 4% fraudulentas\n",
    "    weights = [0.96, 0.04]\n",
    "    \n",
    "    # Gerando dados com padr√µes complexos\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_transacoes,\n",
    "        n_features=n_features,\n",
    "        n_informative=n_informativas,\n",
    "        n_redundant=2,\n",
    "        n_clusters_per_class=2,  # M√∫ltiplos padr√µes de fraude\n",
    "        weights=weights,\n",
    "        flip_y=0.02,  # 2% de ru√≠do nos labels\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Nomes das features baseados em dados banc√°rios reais\n",
    "    feature_names = [\n",
    "        'valor_transacao_log',     # Log do valor da transa√ß√£o\n",
    "        'hora_do_dia',             # Hora da transa√ß√£o (0-23)\n",
    "        'dia_da_semana',           # Dia da semana (1-7)\n",
    "        'freq_transacoes_hora',    # Frequ√™ncia de transa√ß√µes na √∫ltima hora\n",
    "        'valor_medio_30d',         # Valor m√©dio das transa√ß√µes nos √∫ltimos 30 dias\n",
    "        'desvio_padrao_valores',   # Variabilidade hist√≥rica dos valores\n",
    "        'tempo_ultima_transacao',  # Minutos desde a √∫ltima transa√ß√£o\n",
    "        'tentativas_login_24h',    # Tentativas de login nas √∫ltimas 24h\n",
    "        'localizacao_habitual',    # Se a localiza√ß√£o √© habitual (0-1)\n",
    "        'dispositivo_conhecido',   # Se o dispositivo √© conhecido (0-1)\n",
    "        'idade_conta_meses',       # Idade da conta em meses\n",
    "        'saldo_medio_30d',        # Saldo m√©dio dos √∫ltimos 30 dias\n",
    "        'limite_credito_utilizado',  # % do limite de cr√©dito utilizado\n",
    "        'score_comportamental',    # Score do contexto (0-100)\n",
    "        'num_cartoes_ativos',      # N√∫mero de cart√µes ativos\n",
    "        'transacoes_int_30d',      # Transa√ß√µes internacionais nos √∫ltimos 30 dias\n",
    "        'velocidade_digitacao',    # Velocidade de digita√ß√£o normalizada\n",
    "        'padr√£o_normalizado'         # Score de padr√£o normalizado\n",
    "    ]\n",
    "    \n",
    "    # Criando DataFrame\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    df['e_fraude'] = y  # 0 = leg√≠tima, 1 = fraude\n",
    "    \n",
    "    # For√ßando features categ√≥ricas a serem bin√°rias\n",
    "    df['localizacao_habitual'] = (df['localizacao_habitual'] > 0).astype(int)\n",
    "    df['dispositivo_conhecido'] = (df['dispositivo_conhecido'] > 0).astype(int)\n",
    "    \n",
    "    # Verifica√ß√£o da propor√ß√£o de fraudes\n",
    "    fraude_ratio = df['e_fraude'].mean()\n",
    "    if not (0.03 <= fraude_ratio <= 0.05):\n",
    "        print(f\"‚ö†Ô∏è Aviso: Propor√ß√£o de fraudes ({fraude_ratio:.2f}) fora do intervalo esperado (0.03-0.05).\")\n",
    "    \n",
    "    # Valida√ß√£o de features categ√≥ricas\n",
    "    for col in ['localizacao_habitual', 'dispositivo_conhecido']:\n",
    "        if not df[col].isin([0, 1]).all():\n",
    "            print(f\"‚ö†Ô∏è Erro: A coluna {col} cont√©m valores n√£o bin√°rios.\")\n",
    "            raise ValueError(f\"A coluna {col} deve conter apenas valores 0 ou 1.\")\n",
    "    \n",
    "    # Estat√≠sticas do dataset\n",
    "    total = len(df)\n",
    "    fraudulentas = len(df[df['e_fraude'] == 1])\n",
    "    legitimas = len(df[df['e_fraude'] == 0])\n",
    "    \n",
    "    print(f\"‚úÖ Dataset criado com sucesso!\")\n",
    "    print(f\"   üìà Total de transa√ß√µes: {total:,}\")\n",
    "    print(f\"   ‚úÖ Transa√ß√µes leg√≠timas: {legitimas:,} ({legitimas/total*100:.2f}%)\")\n",
    "    print(f\"   üö® Transa√ß√µes fraudulentas: {fraudulentas:,} ({fraudulentas/total*100:.2f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Criando o dataset\n",
    "df_transacoes = criar_dataset_transacoes_financeiras()\n",
    "\n",
    "# ============================================================================\n",
    "# 2. FUN√á√ÉO OBJETIVO MULTI-CRITERIO PARA OTIMIZA√á√ÉO\n",
    "# ============================================================================\n",
    "\n",
    "def funcao_objetivo_fintech(y_true, y_pred, peso_deteccao=0.5, peso_precisao=0.3, peso_experiencia=0.2):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o objetivo que simula os crit√©rios de neg√≥cio de uma fintech\n",
    "    \n",
    "    Par√¢metros:\n",
    "    - y_true: Labels verdadeiros\n",
    "    - y_pred: Predi√ß√µes do modelo\n",
    "    - peso_deteccao: Peso para recall (detectar fraudes)\n",
    "    - peso_precisao: Peso para precis√£o (evitar alarmes falsos)\n",
    "    - peso_experiencia: Peso para experi√™ncia do usu√°rio (baixo FPR)\n",
    "    \n",
    "    Retorna: Score que queremos MAXIMIZAR\n",
    "    \"\"\"\n",
    "    # Valida√ß√£o dos pesos\n",
    "    if not (0 <= peso_deteccao <= 1 and 0 <= peso_precisao <= 1 and 0 <= peso_experiencia <= 1):\n",
    "        print(\"‚ö†Ô∏è Erro: Os pesos devem estar entre 0 e 1.\")\n",
    "        raise ValueError(\"Os pesos devem estar entre 0 e 1.\")\n",
    "    if abs(peso_deteccao + peso_precisao + peso_experiencia - 1.0) > 1e-10:\n",
    "        print(\"‚ö†Ô∏è Erro: Os pesos devem somar 1.\")\n",
    "        raise ValueError(\"Os pesos devem somar 1.\")\n",
    "    \n",
    "    # Calculando m√©tricas fundamentais\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Taxa de falsos positivos (impacta experi√™ncia do usu√°rio)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    \n",
    "    # Alertas para casos extremos\n",
    "    if (fp + tn) == 0:\n",
    "        print(\"‚ö†Ô∏è Aviso: Nenhuma transa√ß√£o negativa detectada. FPR ajustado para 0.\")\n",
    "    if sum(y_pred) == 0:\n",
    "        print(\"‚ö†Ô∏è Aviso: Nenhuma previs√£o positiva feita. Precision ajustada para 0.\")\n",
    "    \n",
    "    # Score de experi√™ncia do usu√°rio (1 - FPR)\n",
    "    experiencia_usuario = 1 - fpr\n",
    "    \n",
    "    # Combina√ß√£o linear ponderada dos objetivos\n",
    "    score_final = (peso_deteccao * recall + \n",
    "                   peso_precisao * precision + \n",
    "                   peso_experiencia * experiencia_usuario)\n",
    "    \n",
    "    return score_final\n",
    "\n",
    "# Fun√ß√£o de scoring para GridSearchCV/RandomizedSearchCV\n",
    "def score_customizado_fintech(estimator, X, y):\n",
    "    \"\"\"Wrapper da fun√ß√£o objetivo para uso no GridSearchCV/RandomizedSearchCV\"\"\"\n",
    "    y_pred = estimator.predict(X)\n",
    "    return funcao_objetivo_fintech(y_true=y, y_pred=y_pred)\n",
    "\n",
    "# ============================================================================\n",
    "# 3. PREPARA√á√ÉO E DIVIS√ÉO DOS DADOS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n=== Preparando os dados para modelagem ===\")\n",
    "\n",
    "# Separando features (X) e target (y)\n",
    "X = df_transacoes.drop('e_fraude', axis=1)\n",
    "y = df_transacoes['e_fraude']\n",
    "\n",
    "# Divis√£o estratificada para manter propor√ß√£o de fraudes\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.25,      # 25% para teste\n",
    "    random_state=42, \n",
    "    strategy=y           # Estratifica√ß√£o\n",
    ")\n",
    "\n",
    "# Normaliza√ß√£o apenas para features num√©ricas\n",
    "colunas_numericas = [col for col in X.columns if col not in ['localizacao_habitual', 'dispositivo_conhecido']]\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = X_train.copy()\n",
    "X_test_norm = X_test.copy()\n",
    "X_train_norm[colunas_numericas] = scaler.fit_transform(X_train[colunas_numericas])\n",
    "X_test_norm[colunas_numericas] = scaler.transform(X_test[colunas_numericas])\n",
    "\n",
    "print(f\"\\n‚úÖ Dados preparados com sucesso:\")\n",
    "print(f\"Conjunto de treinamento: {X_train.shape[0]:,} transa√ß√µes\")\n",
    "print(f\"Conjunto de teste: {X_test.shape[0]:,} transa√ß√µes\")\n",
    "print(f\"Features por transa√ß√£o: {X_train.shape[1]}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. DEFINI√á√ÉO DO ESPA√áO DE BUSCA PARA OTIMIZA√á√ÉO\n",
    "# ===========================================================================\n",
    "\n",
    "print(\"\\n=== Definindo o espa√ßo de busca para otimiza√ß√£o ===\")\n",
    "\n",
    "# Modelo base: Random Forest com peso de classe\n",
    "modelo_rf = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Grid de hiperpar√¢metros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 15, None],  # Ajustado para incluir profundidade menor\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'max_features': ['sqrt', 'log2', max(1, int(0.6 * X.shape[1]))]  # Corre√ß√£o\n",
    "}\n",
    "\n",
    "# Flag para escolher entre GridSearchCV e RandomizedSearchCV\n",
    "use_random_search = True\n",
    "\n",
    "total_combinacoes = 1 if use_random_search else np.prod([len(v) for v in param_grid.values()])\n",
    "if use_random_search:\n",
    "    total_combinacoes = 50  # N√∫mero de itera√ß√µes para RandomizedSearchCV\n",
    "\n",
    "print(f\"\\n‚úÖ Espa√ßo de busca definido:\")\n",
    "print(f\"Total de combina√ß√µes' if not use_random_search else 'itera√ß√µes': {total_combinacoes:,}\")\n",
    "print(f\"Estimativa de tempo: ~{total_combinacoes * 0.2:.0f} segundos\")\n",
    "\n",
    "# ===========================================================================\n",
    "# 5. EXECU√á√ÉO DA OTIMIZA√á√ÉO\n",
    "# ===========================================================================\n",
    "\n",
    "print(\"\\n==== Iniciando a otimiza√ß√£o de hiperpar√¢metros ===\")\n",
    "\n",
    "# Configurando o SearchCV\n",
    "if use_random_search:\n",
    "    searcher_cv = RandomizedSearchCV(\n",
    "        estimator=modelo_rf,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=50,\n",
    "        scoring=scorer_customizado_fintech_score,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        return_train_score=True\n",
    "    )\n",
    "else:\n",
    "    searcher_cv = GridSearchCV(\n",
    "        estimator=modelo_rf_rf,\n",
    "        param_grid=param_grid_grid,\n",
    "        scoring=scorer_customizado_fintech_score,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "# Executando a busca com medi√ß√£o de tempo\n",
    "print(\"Executando busca (pode levar alguns minutos)...\")\n",
    "start_time = time.time()\n",
    "searcher_cv.fit(X_train_norm, y_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Otimiza√ß√£o conclu√≠da em {elapsed_time:.2f} segundos!\")\n",
    "print(f\"Melhor score (CV): {searcher_cv.best_score_:.4f}\")\n",
    "\n",
    "print(f\"\\nMelhor hiperpar√¢metros encontrados:\")\n",
    "for param, value in searcher_cv.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Salvando modelo, scaler e resultados\n",
    "joblib.dump(searcher_cv.best_estimator_, 'modelo_fraudes_rf.pkl')\n",
    "joblib.dump(scaler, 'scaler_fraudes.pkl')\n",
    "resultados_cv = pd.DataFrame(searcher_cv.cv_results_)\n",
    "resultados_cv.to_csv('resultados_search_cv.csv', index=False)\n",
    "print(\"\\nüíæ Modelo, scaler e resultados salvos como 'modelo_fraudes_rf.pkl', 'scaler_fraudes.pkl' e 'resultados_search_cv.csv'\")\n",
    "\n",
    "# ===========================================================================\n",
    "# 6. AVALIA√á√ÉO DO MODELO OTIMIZADO\n",
    "# ===========================================================================\n",
    "\n",
    "print(\"\\n=== Avaliando a performance do modelo otimizado ===\")\n",
    "\n",
    "# Modelo com melhores hiperpar√¢metros\n",
    "modelo_optimizado = searcher_cv.best_estimator_\n",
    "\n",
    "# Predi√ß√µes no conjunto de teste\n",
    "y_pred_test = modelo_optimizado.predict(X_test_norm)\n",
    "y_proba_test = modelo_optimizado.predict_proba(X_test_norm)[:, 1]\n",
    "\n",
    "# M√©tricas detalhadas\n",
    "recall_final = recall_score(y_test, y_pred_test)\n",
    "precision_final = precision_score(y_test, y_pred_test)\n",
    "f1_final = f1_score(y_test, y_pred_test)\n",
    "auc_final = roc_auc_score(y_test, y_proba_test)\n",
    "\n",
    "print(f\"\\nüìà M√©tricas de Performance Final:\")\n",
    "print(f\"Recall (Detec√ß√£o de Fraudes): {recall_final:.4f}\")\n",
    "print(f\"Precis√£o (Qualidade): {precision_final:.4f}\")\n",
    "print(f\"F1-Score: {f1_final:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_final:.4f}\")\n",
    "\n",
    "# Relat√≥rio detalhado de classifica√ß√£o\n",
    "print(\"\\nRelat√≥rio Detalhado de Classifica√ß√£o:\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred_test, \n",
    "                          target_names=['Leg√≠tima', 'Fraude'], \n",
    "                          digits=4))\n",
    "\n",
    "# ===========================================================================\n",
    "# 7. VISUALIZA√á√ïES ESPEC√çFICAS\n",
    "# ===========================================================================\n",
    "\n",
    "# Configura√ß√£o global para plots\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = [12, 12]\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Criando subplots\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "\n",
    "# Plot 1: Matriz de Confus√£o\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "            xticklabels=['Leg√≠tima', 'Fraude'],\n",
    "            yticklabels=['Leg√≠tima', 'Fraude'])\n",
    "ax1.set_title('Predi√ß√£o Matriz de Confus√£o', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Predi√ß√£o')\n",
    "ax1.set_ylabel('Real')\n",
    "\n",
    "# Plot 2: Import√¢ncia das Features\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'score': modelo_optmodelo_score.importances_\n",
    "}).sort_values('score', ascending=False).head(10)\n",
    "\n",
    "ax2.barh(range(len(feature_importance_df))),\n",
    "feature_importance_df['score'],\n",
    ")\n",
    "ax2.set_yticks(range(len(feature_importance_df)))\n",
    "ax2.set_yticklabels(feature_importance_df['feature'])\n",
    "ax2.set_title('Top 10 Features Mais Importantes')\n",
    "ax2.set_xlabel('Import√¢ncia')\n",
    "ax2.grid(axis='x', alpha=0.2)\n",
    "\n",
    "# Plot 3: Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_test)\n",
    "ax3.plot(fpr, tpr, color='blue', linewidth=2, label=f'ROC (AUC={auc_final:.4f})')\n",
    "ax3.plot([0, 1], [0, 1], 'r--', alpha=0.5, label='Random')\n",
    "ax3.set_xlabel('Taxa de Falsos Positivos')\n",
    "ax3.set_ylabel('Taxa de Verdadeiros Positivos')\n",
    "ax3.set_title('Curva ROC')\n",
    "ax3.legend()\n",
    "ax3.grid(alpha=0.2)\n",
    "\n",
    "# Plot 4: An√°lise de Converg√™ncia (dispers√£o)\n",
    "scores_mean = resultados_cv['mean_test_score']\n",
    "ax4.scatter(range(len(scores_mean)), scores_mean, c=scores_mean, cmap='viridis', alpha=0.7)\n",
    "ax4.axhline(y=searcher_cv.best_score_, color='red', linestyle='--', \n",
    "            label=f'Melhor Score: {searcher_cv.best_score_:.4f}')\n",
    "ax4.set_xlabel('Configura√ß√£o de Hiperpar√¢metros')\n",
    "ax4.set_ylabel('Score Cross-Validation')\n",
    "ax4.set_title('Converg√™ncia da Otimiza√ß√£o')\n",
    "ax4.legend()\n",
    "ax4.grid(alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ===========================================================================\n",
    "# 8. AN√ÅLISE DE TRADE-OFFS DE NEG√ìCIO\n",
    "# ===========================================================================\n",
    "\n",
    "print(\"\\n=== An√°lise de Trade-offs de Neg√≥cio ===\")\n",
    "\n",
    "# Calculando impacto financeiro hipot√©tico\n",
    "total_transacoes_teste = len(y_test)\n",
    "fraudes_reais = sum(y_test)\n",
    "legitimas_reais = total_transacoes_teste - fraudes_reais\n",
    "\n",
    "# Valores m√©dios hipot√©ticos por transa√ß√£o\n",
    "valor_medio_fraude = 850.0     # R$ 850 por fraude\n",
    "custo_falso_positivo = 12.0    # R$ 12 de custo operacional por FP\n",
    "\n",
    "# Calculando custos\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Benef√≠cios: fraudes detectadas\n",
    "beneficio_deteccao = tp * valor_medio_fraude\n",
    "\n",
    "# Custos: fraudes n√£o detectadas + falsos positivos\n",
    "custo_fraudes_perdidas = fn * valor_medio_fraude\n",
    "custo_falsos_positivos = fp * custo_falso_positivo\n",
    "custo_total = custo_fraudes_perdidas + custo_falsos_positivos\n",
    "\n",
    "# ROI do sistema\n",
    "if custo_total > 0:\n",
    "    roi = (beneficio_deteccao - custo_total) / custo_total * 100\n",
    "else:\n",
    "    roi = 0 if beneficio_deteccao == 0 else float('inf')\n",
    "\n",
    "print(f\"\\nImpacto Financeiro Estimado (no conjunto de teste):\")\n",
    "print(f\"Benef√≠cio - Fraudes detectadas: R$ {beneficio_deteccao:,.2f}\")\n",
    "print(f\"Custo - Fraudes n√£o detectadas: R$ {custo_fraudes_perdidas:,.2f}\")\n",
    "print(f\"Custo - Falsos positivos: R$ {custo_falsos_positivos:,.2f}\")\n",
    "print(f\"ROI do Sistema: {roi:.1f}%{' (infinito)' if roi == float('inf') else ''}\")\n",
    "\n",
    "# ===========================================================================\n",
    "# 9. INSIGHTS E CONCLUS√ïES\n",
    "# ===========================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"INSIGHTS E CONCLUS√ïES - EXEMPLO 1\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "RESULTADOS DA OTIMIZA√á√ÉO:\n",
    "\n",
    "‚úÖ Performance Alcan√ßada:\n",
    "   ‚Ä¢ Recall (Detec√ß√£o): {recall_final:.1%} das fraudes identificadas\n",
    "   ‚Ä¢ Precision (Qualidade): {precision_final:.1%} das detec√ß√µes s√£o corretas  \n",
    "   ‚Ä¢ F1-Score Balanceado: {f1_final:.4f}\n",
    "   ‚Ä¢ AUC-ROC: {auc_final:.4f} (excelente discrimina√ß√£o)\n",
    "\n",
    "üîß Hiperpar√¢metros Otimizados:\n",
    "   ‚Ä¢ N√∫mero de √°rvores: {searcher_cv.best_params_['n_estimators']}\n",
    "   ‚Ä¢ Profundidade m√°xima: {searcher_cv.best_params_['max_depth']}\n",
    "   ‚Ä¢ Crit√©rio de divis√£o: {searcher_cv.best_params_['criterion']}\n",
    "\n",
    "üí° APLICA√á√ïES PR√ÅTICAS:\n",
    "\n",
    "1. Otimiza√ß√£o Cont√≠nua:\n",
    "   ‚Ä¢ Re-execu√ß√£o autom√°tica da busca com novos dados\n",
    "   ‚Ä¢ Adapta√ß√£o a mudan√ßas nos padr√µes de fraude\n",
    "   ‚Ä¢ Monitoramento de performance em produ√ß√£o\n",
    "\n",
    "2. Balanceamento de Objetivos:\n",
    "   ‚Ä¢ Trade-off entre detec√ß√£o e experi√™ncia do usu√°rio\n",
    "   ‚Ä¢ Minimiza√ß√£o de custos operacionais\n",
    "   ‚Ä¢ Maximiza√ß√£o do ROI do sistema antifraude\n",
    "\n",
    "3. Escalabilidade:\n",
    "   ‚Ä¢ Paraleliza√ß√£o da busca de hiperpar√¢metros\n",
    "   ‚Ä¢ Otimiza√ß√£o distribu√≠da para grandes volumes\n",
    "   ‚Ä¢ AutoML para ajuste autom√°tico\n",
    "\n",
    "üî¨ CONCEITOS MATEM√ÅTICOS DEMONSTRADOS:\n",
    "\n",
    "‚Ä¢ Otimiza√ß√£o combinatorial discreta (Grid/Random Search)\n",
    "‚Ä¢ Fun√ß√£o objetivo multi-crit√©rio com pesos ajust√°veis\n",
    "‚Ä¢ Valida√ß√£o cruzada estratificada\n",
    "‚Ä¢ An√°lise de import√¢ncia por impureza de Gini\n",
    "‚Ä¢ Trade-off bias-vari√¢ncia em ensemble methods\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nüìö Pr√≥ximo: Exemplo 2 - Otimiza√ß√£o Cont√≠nua de Threshold\")\n",
    "print(f\"üîó Reposit√≥rio: https://github.com/maurizioprizzi/otimizacao-aplicada-ciencia-dados\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
